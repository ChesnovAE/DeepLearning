{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network():\n",
    "    classifier = tf.keras.models.Sequential()\n",
    "    classifier.add(tf.keras.layers.Conv2D(32, (3, 3), input_shape=(64,64,3), activation='relu'))\n",
    "    classifier.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    classifier.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    classifier.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    classifier.add(tf.keras.layers.Flatten())\n",
    "    classifier.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    classifier.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processor = ImageDataGenerator(rescale=1./255, # нормируем\n",
    "                                     shear_range=0.2, # поворачиваем\n",
    "                                     zoom_range=0.2, # зуммируем\n",
    "                                     horizontal_flip=True) # рандомно транспорнируем?\n",
    "test_processor = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'dataset',\n",
       " 'cnn.py',\n",
       " 'logs',\n",
       " 'cnn_with_keras.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'cnn_homework_solution.py']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = train_processor.flow_from_directory('dataset/training_set',\n",
    "                                            target_size=(64,64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')\n",
    "test = train_processor.flow_from_directory('dataset/test_set',\n",
    "                                           target_size=(64,64),\n",
    "                                           batch_size=32,\n",
    "                                           class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = build_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 41s 413ms/step - loss: 0.6977 - accuracy: 0.5056 - val_loss: 0.6914 - val_accuracy: 0.5219\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 0.6799 - accuracy: 0.5713 - val_loss: 0.6667 - val_accuracy: 0.6125\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 0.6558 - accuracy: 0.6175 - val_loss: 0.6525 - val_accuracy: 0.6281\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 36s 361ms/step - loss: 0.6205 - accuracy: 0.6622 - val_loss: 0.6484 - val_accuracy: 0.6156\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 33s 325ms/step - loss: 0.6046 - accuracy: 0.6678 - val_loss: 0.5777 - val_accuracy: 0.7047\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 32s 320ms/step - loss: 0.5978 - accuracy: 0.6694 - val_loss: 0.5764 - val_accuracy: 0.7078\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.5963 - accuracy: 0.6772 - val_loss: 0.5718 - val_accuracy: 0.7000\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 32s 320ms/step - loss: 0.5597 - accuracy: 0.7169 - val_loss: 0.5413 - val_accuracy: 0.7312\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 38s 384ms/step - loss: 0.5686 - accuracy: 0.7022 - val_loss: 0.5827 - val_accuracy: 0.6953\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.5421 - accuracy: 0.7253 - val_loss: 0.5522 - val_accuracy: 0.7219\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 33s 331ms/step - loss: 0.5288 - accuracy: 0.7294 - val_loss: 0.5453 - val_accuracy: 0.7078\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 33s 329ms/step - loss: 0.5418 - accuracy: 0.7231 - val_loss: 0.5257 - val_accuracy: 0.7250\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 0.5241 - accuracy: 0.7428 - val_loss: 0.5206 - val_accuracy: 0.7266\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 0.5143 - accuracy: 0.7478 - val_loss: 0.5362 - val_accuracy: 0.7125\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 0.5105 - accuracy: 0.7409 - val_loss: 0.5189 - val_accuracy: 0.7437\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 33s 325ms/step - loss: 0.5046 - accuracy: 0.7491 - val_loss: 0.5078 - val_accuracy: 0.7641\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 32s 325ms/step - loss: 0.5015 - accuracy: 0.7606 - val_loss: 0.4836 - val_accuracy: 0.7594\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 33s 325ms/step - loss: 0.4875 - accuracy: 0.7631 - val_loss: 0.5054 - val_accuracy: 0.7563\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 0.4963 - accuracy: 0.7628 - val_loss: 0.4957 - val_accuracy: 0.7516\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.4822 - accuracy: 0.7684 - val_loss: 0.4935 - val_accuracy: 0.7516\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 0.4622 - accuracy: 0.7850 - val_loss: 0.4734 - val_accuracy: 0.7766\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.4850 - accuracy: 0.7650 - val_loss: 0.4901 - val_accuracy: 0.7844\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 34s 338ms/step - loss: 0.4538 - accuracy: 0.7847 - val_loss: 0.4695 - val_accuracy: 0.7844\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 33s 331ms/step - loss: 0.4542 - accuracy: 0.7791 - val_loss: 0.4772 - val_accuracy: 0.7750\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 0.4636 - accuracy: 0.7800 - val_loss: 0.4752 - val_accuracy: 0.8016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1329d8650>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(train,\n",
    "                         steps_per_epoch=100,\n",
    "                         epochs=25,\n",
    "                         validation_data=test,\n",
    "                         validation_steps=20,\n",
    "                         callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.expand_dims(test_image, axis=0) # добавляем размерность для батча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "if result[0, 0] == 1:\n",
    "    print('Dog')\n",
    "else:\n",
    "    print('Cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitac641723bb38424994ea6184b3743d2f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
